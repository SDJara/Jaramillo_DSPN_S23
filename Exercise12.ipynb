{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xdZ1WjBmtDf"
      },
      "source": [
        "# Exercise 12: Cross Validation\n",
        "-----\n",
        "\n",
        "In this exercise, we'll practice implementing cross validation techniques, including leave-one-out and k-fold cross validation. We'll use the `PimaIndiansDiabetes2` practice dataset, which has medical data on a group of Pima Native American women, including whether or not they have diabetes. This dataset is part of the `mlbench` package. We'll be using each person's medical history to predict whether or not they have been diagnosed with diabetes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BubJSLTamtDg"
      },
      "source": [
        "# 1: Data (1 pts)\n",
        "---\n",
        "\n",
        "Load the `tidyverse`, `boot`, and `mlbench` packages (you may need to install `boot` and `mlbench`).\n",
        "\n",
        "Load the `PimaIndiansDiabetes2` dataset using the `data()` function. Drop the `insulin` column (it just has a lot of missing data) and then drop `NA`s from the rest of the dataset. Save your updated dataset to a new variable name. Finally, print the dimensions of your new dataset, and look at the first few lines of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QNuKGb6emtDg",
        "outputId": "046552cd-6060-412c-87b5-dfde93a3bd06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 9</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>pregnant</th><th scope=col>glucose</th><th scope=col>pressure</th><th scope=col>triceps</th><th scope=col>insulin</th><th scope=col>mass</th><th scope=col>pedigree</th><th scope=col>age</th><th scope=col>diabetes</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>6</td><td>148</td><td>72</td><td>35</td><td> NA</td><td>33.6</td><td>0.627</td><td>50</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>1</td><td> 85</td><td>66</td><td>29</td><td> NA</td><td>26.6</td><td>0.351</td><td>31</td><td>neg</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>8</td><td>183</td><td>64</td><td>NA</td><td> NA</td><td>23.3</td><td>0.672</td><td>32</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>1</td><td> 89</td><td>66</td><td>23</td><td> 94</td><td>28.1</td><td>0.167</td><td>21</td><td>neg</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>0</td><td>137</td><td>40</td><td>35</td><td>168</td><td>43.1</td><td>2.288</td><td>33</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>5</td><td>116</td><td>74</td><td>NA</td><td> NA</td><td>25.6</td><td>0.201</td><td>30</td><td>neg</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 9\n\n| <!--/--> | pregnant &lt;dbl&gt; | glucose &lt;dbl&gt; | pressure &lt;dbl&gt; | triceps &lt;dbl&gt; | insulin &lt;dbl&gt; | mass &lt;dbl&gt; | pedigree &lt;dbl&gt; | age &lt;dbl&gt; | diabetes &lt;fct&gt; |\n|---|---|---|---|---|---|---|---|---|---|\n| 1 | 6 | 148 | 72 | 35 |  NA | 33.6 | 0.627 | 50 | pos |\n| 2 | 1 |  85 | 66 | 29 |  NA | 26.6 | 0.351 | 31 | neg |\n| 3 | 8 | 183 | 64 | NA |  NA | 23.3 | 0.672 | 32 | pos |\n| 4 | 1 |  89 | 66 | 23 |  94 | 28.1 | 0.167 | 21 | neg |\n| 5 | 0 | 137 | 40 | 35 | 168 | 43.1 | 2.288 | 33 | pos |\n| 6 | 5 | 116 | 74 | NA |  NA | 25.6 | 0.201 | 30 | neg |\n\n",
            "text/latex": "A data.frame: 6 × 9\n\\begin{tabular}{r|lllllllll}\n  & pregnant & glucose & pressure & triceps & insulin & mass & pedigree & age & diabetes\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n\\hline\n\t1 & 6 & 148 & 72 & 35 &  NA & 33.6 & 0.627 & 50 & pos\\\\\n\t2 & 1 &  85 & 66 & 29 &  NA & 26.6 & 0.351 & 31 & neg\\\\\n\t3 & 8 & 183 & 64 & NA &  NA & 23.3 & 0.672 & 32 & pos\\\\\n\t4 & 1 &  89 & 66 & 23 &  94 & 28.1 & 0.167 & 21 & neg\\\\\n\t5 & 0 & 137 & 40 & 35 & 168 & 43.1 & 2.288 & 33 & pos\\\\\n\t6 & 5 & 116 & 74 & NA &  NA & 25.6 & 0.201 & 30 & neg\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  pregnant glucose pressure triceps insulin mass pedigree age diabetes\n",
              "1 6        148     72       35       NA     33.6 0.627    50  pos     \n",
              "2 1         85     66       29       NA     26.6 0.351    31  neg     \n",
              "3 8        183     64       NA       NA     23.3 0.672    32  pos     \n",
              "4 1         89     66       23       94     28.1 0.167    21  neg     \n",
              "5 0        137     40       35      168     43.1 2.288    33  pos     \n",
              "6 5        116     74       NA       NA     25.6 0.201    30  neg     "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 8</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>pregnant</th><th scope=col>glucose</th><th scope=col>pressure</th><th scope=col>triceps</th><th scope=col>mass</th><th scope=col>pedigree</th><th scope=col>age</th><th scope=col>diabetes</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>6</td><td>148</td><td>72</td><td>35</td><td>33.6</td><td>0.627</td><td>50</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>1</td><td> 85</td><td>66</td><td>29</td><td>26.6</td><td>0.351</td><td>31</td><td>neg</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>1</td><td> 89</td><td>66</td><td>23</td><td>28.1</td><td>0.167</td><td>21</td><td>neg</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>0</td><td>137</td><td>40</td><td>35</td><td>43.1</td><td>2.288</td><td>33</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>7</th><td>3</td><td> 78</td><td>50</td><td>32</td><td>31.0</td><td>0.248</td><td>26</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>9</th><td>2</td><td>197</td><td>70</td><td>45</td><td>30.5</td><td>0.158</td><td>53</td><td>pos</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 8\n\n| <!--/--> | pregnant &lt;dbl&gt; | glucose &lt;dbl&gt; | pressure &lt;dbl&gt; | triceps &lt;dbl&gt; | mass &lt;dbl&gt; | pedigree &lt;dbl&gt; | age &lt;dbl&gt; | diabetes &lt;fct&gt; |\n|---|---|---|---|---|---|---|---|---|\n| 1 | 6 | 148 | 72 | 35 | 33.6 | 0.627 | 50 | pos |\n| 2 | 1 |  85 | 66 | 29 | 26.6 | 0.351 | 31 | neg |\n| 4 | 1 |  89 | 66 | 23 | 28.1 | 0.167 | 21 | neg |\n| 5 | 0 | 137 | 40 | 35 | 43.1 | 2.288 | 33 | pos |\n| 7 | 3 |  78 | 50 | 32 | 31.0 | 0.248 | 26 | pos |\n| 9 | 2 | 197 | 70 | 45 | 30.5 | 0.158 | 53 | pos |\n\n",
            "text/latex": "A data.frame: 6 × 8\n\\begin{tabular}{r|llllllll}\n  & pregnant & glucose & pressure & triceps & mass & pedigree & age & diabetes\\\\\n  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n\\hline\n\t1 & 6 & 148 & 72 & 35 & 33.6 & 0.627 & 50 & pos\\\\\n\t2 & 1 &  85 & 66 & 29 & 26.6 & 0.351 & 31 & neg\\\\\n\t4 & 1 &  89 & 66 & 23 & 28.1 & 0.167 & 21 & neg\\\\\n\t5 & 0 & 137 & 40 & 35 & 43.1 & 2.288 & 33 & pos\\\\\n\t7 & 3 &  78 & 50 & 32 & 31.0 & 0.248 & 26 & pos\\\\\n\t9 & 2 & 197 & 70 & 45 & 30.5 & 0.158 & 53 & pos\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  pregnant glucose pressure triceps mass pedigree age diabetes\n",
              "1 6        148     72       35      33.6 0.627    50  pos     \n",
              "2 1         85     66       29      26.6 0.351    31  neg     \n",
              "4 1         89     66       23      28.1 0.167    21  neg     \n",
              "5 0        137     40       35      43.1 2.288    33  pos     \n",
              "7 3         78     50       32      31.0 0.248    26  pos     \n",
              "9 2        197     70       45      30.5 0.158    53  pos     "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# INSERT CODE HERE\n",
        "#install.packages(\"boot\")\n",
        "#install.packages(\"mlbench\")\n",
        "\n",
        "require(boot)\n",
        "require(mlbench)\n",
        "require(tidyverse)\n",
        "\n",
        "\n",
        "data(PimaIndiansDiabetes2)\n",
        "\n",
        "head(PimaIndiansDiabetes2)\n",
        "\n",
        "df <- PimaIndiansDiabetes2 %>%\n",
        "  select(-c(insulin))%>%\n",
        "  drop_na()\n",
        "\n",
        "head(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BRVQiWSmtDh"
      },
      "source": [
        "(Note that in medical contexts, `pedigree` refers to a system of measuring family history of a condition. So here, higher numbers mean greater family history of diabetes. You can read more about this dataset [here](https://rdrr.io/cran/mlbench/man/PimaIndiansDiabetes.html).)\n",
        "\n",
        "# 2. Leave-one-out Cross Validation (4 pts)\n",
        "\n",
        "In the tutorial, we learned how to fit leave-one-out cross validation using the `cv.glm` function from the `boot` package. But we can also do this manually using `predict()` like we have in the past.\n",
        "\n",
        "Let's predict `diabetes`, a dichotomous outcome, using all the other variables in our modified dataset. \n",
        "\n",
        "First, fit a logistic regression model using all of the observations except the very first one. Then use your fitted model to predict whether your holdout case is positive or negative for diabetes. Remember that logistic regression coefficients are in **log-odds**, meaning that if an output is positive, the probability of the outcome is greater than 50%; if the output is negative, the probability of the outcome is less than 50%. \n",
        "\n",
        "Compare your result to the actual response in row one above. Did your model correctly classify this observation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RDyry5h_mtDi",
        "outputId": "b12aeb61-aee1-40c3-9977-b824626de6a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'1'"
            ],
            "text/markdown": "'1'",
            "text/latex": "'1'",
            "text/plain": [
              "[1] \"1\""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1</li><li>8</li></ol>\n"
            ],
            "text/markdown": "1. 1\n2. 8\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 1\n\\item 8\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 1 8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>531</li><li>8</li></ol>\n"
            ],
            "text/markdown": "1. 531\n2. 8\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 531\n\\item 8\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 531   8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         actual\n",
              "predicted neg pos\n",
              "      pos   0   1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Accuracy: 1\"\n"
          ]
        }
      ],
      "source": [
        "test <- df[1, ]\n",
        "rownames(test)\n",
        "\n",
        "train <- df[-1,]\n",
        "\n",
        "dim(test) \n",
        "dim(train)\n",
        "\n",
        "\n",
        "Diabetes_test=test$diabetes\n",
        "\n",
        "glm.fit=glm(diabetes~ ., data=train, family=binomial) \n",
        "\n",
        "glm.probs=predict(glm.fit, test, type=\"response\")\n",
        "glm.pred=rep(\"neg\",nrow(test)) \n",
        "glm.pred[glm.probs>0.5] = \"pos\"\n",
        "\n",
        "\n",
        "confusion_df = data.frame(glm.pred, Diabetes_test) \n",
        "colnames(confusion_df) = c('predicted', 'actual')\n",
        "\n",
        "\n",
        "table(confusion_df)\n",
        "\n",
        "print(paste(\"Accuracy:\",mean(confusion_df$predicted == confusion_df$actual)))\n",
        "\n",
        "#Yes, we got the correct classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIPpDdd0mtDi"
      },
      "source": [
        "So we just calculated a single iteration of LOOCV. We used 531 rows of our data to fit a model to predict the outcome of the last row. \n",
        "\n",
        "Below, use a `for` loop to iterate through the rest of your dataset doing the same thing. You will need to:\n",
        "* Create a data frame `results` with two columns: one named `actual` which holds the true classification for each observation, and one named `predicted`, which should be filled with `NA`s. This is where you'll store the output of your loop.\n",
        "* Create a loop that runs through each row of your data, pulls that observation out, trains your model on the remaining data, and then tests the fitted model on your test observation.\n",
        "* Store your model *predictions* (\"pos\" or \"neg\" -- not the log-odds) in the `predicted` column of your `results` dataframe\n",
        "\n",
        "After you run your loop, print the first few lines of `results`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5Z1ijm_PmtDj",
        "outputId": "4d7a3a82-970f-44a7-ddcc-e90ad9b5370a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Actual</th><th scope=col>Predicted</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>pos</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>neg</td><td>neg</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>neg</td><td>neg</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>pos</td><td>pos</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>pos</td><td>neg</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>pos</td><td>pos</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 2\n\n| <!--/--> | Actual &lt;fct&gt; | Predicted &lt;chr&gt; |\n|---|---|---|\n| 1 | pos | pos |\n| 2 | neg | neg |\n| 3 | neg | neg |\n| 4 | pos | pos |\n| 5 | pos | neg |\n| 6 | pos | pos |\n\n",
            "text/latex": "A data.frame: 6 × 2\n\\begin{tabular}{r|ll}\n  & Actual & Predicted\\\\\n  & <fct> & <chr>\\\\\n\\hline\n\t1 & pos & pos\\\\\n\t2 & neg & neg\\\\\n\t3 & neg & neg\\\\\n\t4 & pos & pos\\\\\n\t5 & pos & neg\\\\\n\t6 & pos & pos\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Actual Predicted\n",
              "1 pos    pos      \n",
              "2 neg    neg      \n",
              "3 neg    neg      \n",
              "4 pos    pos      \n",
              "5 pos    neg      \n",
              "6 pos    pos      "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize `results` data frame\n",
        "# INSERT CODE HERE\n",
        "results <- data.frame(Actual = df$diabetes, Predicted = NA)\n",
        "\n",
        "#for loop\n",
        "for (i in 1:nrow(results)){ #don't forget to change this to your data set name\n",
        "    # separate individual observation `i` from the rest of your data\n",
        "    # INSERT CODE HERE\n",
        "    test <- df[i, ]\n",
        "\n",
        "    train <- df[-i,]\n",
        "    \n",
        "    # train your model\n",
        "    # INSERT CODE HERE\n",
        "    glm.fit=glm(diabetes~ ., data=train, family=binomial) \n",
        "\n",
        "    # test model on hold out observation\n",
        "    # INSERT CODE HERE\n",
        "    glm.probs=predict(glm.fit, test, type=\"response\")\n",
        "\n",
        "    \n",
        "\n",
        "    # classify model prediction as \"pos\" or \"neg\" and add to `results`\n",
        "    # INSERT CODE HERE\n",
        "    results[i, \"Predicted\"] <- rep(\"neg\",nrow(test))\n",
        "    results[i, \"Predicted\"][glm.probs>0.5] = \"pos\"\n",
        "   \n",
        "}\n",
        "\n",
        "head(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42Jng_EEmtDk"
      },
      "source": [
        "Now, calculate the overall error of your model. What proportion of cases were incorrectly classified?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SYhKS5HimtDk",
        "outputId": "0879a9af-4e73-4cae-c3b9-0ecd76a07995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Accuracy: 0.778195488721805\"\n"
          ]
        }
      ],
      "source": [
        "# INSERT CODE HERE\n",
        "print(paste(\"Accuracy:\",mean(results$Predicted == results$Actual)))\n",
        "\n",
        "#About 78% accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1TwL8BimtDl"
      },
      "source": [
        "# 3. Compare to `cv.glm` (3 pts)\n",
        "\n",
        "Now, let's compare this result to the `cv.glm` function. Using the tutorial as a guide, use `cv.glm` to run LOOCV on the data, using the same model (i.e., still using all of the variables to predict diabetes diagnosis).\n",
        "\n",
        "Note that, because this is a `classification` problem and not a regression problem like in the tutorial, we need to adjust the `cost` argument of `cv.glm`. We can read more about this in the docs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wIUAW1AtmtDl",
        "outputId": "381478c5-1ea0-4b49-8f1e-beba56e0b7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.221804511278196</li><li>0.222115438973376</li></ol>\n"
            ],
            "text/markdown": "1. 0.221804511278196\n2. 0.222115438973376\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.221804511278196\n\\item 0.222115438973376\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 0.2218045 0.2221154"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#?cv.glm\n",
        "set.seed(1)\n",
        "glm.fit=glm(diabetes~ ., data=df, family=binomial) \n",
        "\n",
        "cost <- function(r, pi = 0) mean(abs(r-pi) > 0.5)\n",
        "\n",
        "cv.err  = cv.glm(df, glm.fit, K=nrow(df), cost = cost)\n",
        "\n",
        "cv.err$delta "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWhbyxtymtDl"
      },
      "source": [
        "Here, we see `cost` is defined as: \n",
        "> \"A function of two vector arguments specifying the cost function for the cross-validation. The first argument to cost should correspond to the **observed responses** and the second argument should correspond to the **predicted or fitted responses** from the generalized linear model.\"\n",
        "\n",
        "In the example code (scroll to bottom of the docs), we see that the appropriate cost function for a binary classification is \n",
        "\n",
        "``\n",
        "cost <- function(r, pi = 0) mean(abs(r-pi) > 0.5)\n",
        "``\n",
        "\n",
        "Where `r` is the vector of observed responses (technically \"pos\" and \"neg\", but R treats these as 1 and 0 under the hood), and `pi` is the vector of *probabilities* (not log-odds) fit by the model. Thus, this boils down to our error: what proportion of observations were incorrectly classified. You will need to include this code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bJiCmfqomtDl",
        "outputId": "df25bc18-aa82-4b03-c662-6427e2e109ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Time difference of 37.58621 secs"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plot without title"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC1lBMVEUAAAABAQECAgIDAwME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\nkCBASBAgJAj4/wscNKOimdx8AAAAAElFTkSuQmCC"
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ],
      "source": [
        "# INSERT CODE HERE\n",
        "#?cv.glm\n",
        "set.seed(1)\n",
        "\n",
        "cv.error = rep(0,10) \n",
        "start.time <- Sys.time()\n",
        "for (i in 1:10) {\n",
        "    glm.fit=glm(diabetes~ ., data=df, family=binomial) \n",
        "\n",
        "    cv.err[i]  = cv.glm(df, glm.fit)$delta[1]\n",
        "}\n",
        "end.time <- Sys.time()\n",
        "\n",
        "LOOtime <- end.time-start.time \n",
        "LOOtime\n",
        "\n",
        "plot(1:10,cv.error) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcEuGX3FmtDm"
      },
      "source": [
        "How do your results compare to your manual LOOCV above?\n",
        "\n",
        "> * *Write response here*\n",
        ">\n",
        "> They look pretty much the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y2tL4NpmtDm"
      },
      "source": [
        "# 4. Adjusting K and Reflection (2 pts)\n",
        "\n",
        "Recall that LOOCV has some drawbacks. In particular, it has quite high *variance* which can lead to poor performance on new test data. We can reduce this variance by increasing K.\n",
        "\n",
        "Below, re-run your cross validation using `cv.glm` with `k` set to 3, 5, 10, and 15. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vZYq_NQlmtDm",
        "scrolled": true,
        "outputId": "081656a7-4519-43ea-9217-ffcd183277f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.210526315789474</li><li>0.21680846853977</li></ol>\n"
            ],
            "text/markdown": "1. 0.210526315789474\n2. 0.21680846853977\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.210526315789474\n\\item 0.21680846853977\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 0.2105263 0.2168085"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.216165413533835</li><li>0.218444372208717</li></ol>\n"
            ],
            "text/markdown": "1. 0.216165413533835\n2. 0.218444372208717\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.216165413533835\n\\item 0.218444372208717\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 0.2161654 0.2184444"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.223684210526316</li><li>0.223094154559331</li></ol>\n"
            ],
            "text/markdown": "1. 0.223684210526316\n2. 0.223094154559331\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.223684210526316\n\\item 0.223094154559331\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 0.2236842 0.2230942"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.227443609022556</li><li>0.228185595567867</li></ol>\n"
            ],
            "text/markdown": "1. 0.227443609022556\n2. 0.228185595567867\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.227443609022556\n\\item 0.228185595567867\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 0.2274436 0.2281856"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "set.seed(1)\n",
        "#INSERT CODE BELOW\n",
        "glm.fit=glm(diabetes~ ., data=df, family=binomial) \n",
        "\n",
        "cost <- function(r, pi = 0) mean(abs(r-pi) > 0.5)\n",
        "\n",
        "# K = 3\n",
        "cv.err  = cv.glm(df, glm.fit, K=3, cost = cost)\n",
        "cv.err$delta \n",
        "\n",
        "# K = 5\n",
        "cv.err  = cv.glm(df, glm.fit, K=5, cost = cost)\n",
        "cv.err$delta \n",
        "\n",
        "# K = 10\n",
        "cv.err  = cv.glm(df, glm.fit, K=10, cost = cost)\n",
        "cv.err$delta \n",
        "\n",
        "# K = 15\n",
        "cv.err  = cv.glm(df, glm.fit, K=15, cost = cost)\n",
        "cv.err$delta "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI5Y1OqOmtDn"
      },
      "source": [
        "#### Reflection\n",
        "\n",
        "How do your errors compare to your LOOCV error above? How do they change as k increases?\n",
        "> * *Write response here:* Increasing levels of k results in slightly lower error.\n",
        "\n",
        "\n",
        "If you change the random seed above, you'll get slightly different errors. If you were to do the same with your LOOCV above , would you expect to get different results each time? Why or why not?\n",
        "> * *Write response here*: No, I would not expect the results to change for LOOCV comapared to smaller k folds. LOOCV is fully exhaustive and because only one is left out the train group generally doesn't change that much. With smaller k folds, you are randomly subsetting k=X times.\n",
        "\n",
        "\n",
        "**DUE:** 5pm March 27, 2023\n",
        "\n",
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *Someone's Name*\n",
        "> \n",
        ">\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}